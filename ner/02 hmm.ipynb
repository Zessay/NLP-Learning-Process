{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, N, M, word2id, tag2id):\n",
    "        '''\n",
    "        N: 状态数，对应存在的标注的种类\n",
    "        M: 观测数，对应有多少个不同的字\n",
    "        '''\n",
    "        self.N = N\n",
    "        self.M = M\n",
    "        \n",
    "        # 状态转移概率矩阵\n",
    "        self.A = torch.zeros(N, N)\n",
    "        # 观测概率矩阵，B[i][j]表示i状态下生成j观测的概率\n",
    "        self.B = torch.zeros(N, M)\n",
    "        # 初始状态概率\n",
    "        self.Pi = torch.zeros(N)\n",
    "        self.word2id = word2id   # 将单词映射为ID\n",
    "        self.tag2id = tag2id     # 将标签映射为ID\n",
    "        \n",
    "    def train(self, word_lists, tag_lists):\n",
    "        '''\n",
    "        可以使用极大似然估计法来估计隐马模型的参数\n",
    "        @params:\n",
    "        word_lists: 二维list型，每个元素由字组成，如['担', '任', '科', '员']\n",
    "        tag_lists: 二维list型，每个元素是对应的标注，如['O', 'O', 'B-TITLE', 'E-TITLE']\n",
    "        '''\n",
    "        assert len(tag_lists) == len(word_lists)\n",
    "        \n",
    "        # 估计转移概率矩阵\n",
    "        for tag_list in tag_lists:\n",
    "            seq_len = len(tag_list)\n",
    "            for i in range(seq_len - 1):\n",
    "                current_tagid = self.tag2id[tag_list[i]]\n",
    "                next_tagid = self.tag2id[tag_list[i+1]]\n",
    "                self.A[current_tagid][next_tagid] += 1 \n",
    "        # 如果某元素没有出现过，进行平滑\n",
    "        self.A[self.A == 0.] = 1e-10\n",
    "        self.A = self.A / self.A.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        \n",
    "        # 估计观测概率矩阵\n",
    "        for tag_list, word_list in zip(tag_lists, word_lists):\n",
    "            assert len(tag_list) == len(word_list)\n",
    "            for tag, word in zip(tag_list, word_list):\n",
    "                tag_id = self.tag2id[tag]\n",
    "                word_id = self.word2id[word]\n",
    "                self.B[tag_id][word_id] += 1\n",
    "        self.B[self.B == 0.] = 1e-10\n",
    "        self.B = self.B / self.B.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        \n",
    "        # 估计初始状态概率\n",
    "        for tag_list in tag_lists:\n",
    "            init_tagid = self.tag2id[tag_list[0]]\n",
    "            self.Pi[init_tagid] += 1\n",
    "        self.Pi[self.Pi == 0] = 1e-10\n",
    "        self.Pi = self.Pi / self.Pi.sum()\n",
    "        \n",
    "    def test(self, word_lists):\n",
    "        '''\n",
    "        用于最终的预测\n",
    "        '''\n",
    "        pred_tag_lists = []\n",
    "        for word_list in word_lists:\n",
    "            pred_tag_list = self.decoding(word_list)\n",
    "            pred_tag_lists.append(pred_tag_list)\n",
    "        return pred_tag_lists\n",
    "    \n",
    "    \n",
    "    def decoding(self, word_list):\n",
    "        '''\n",
    "        使用维特比算法对给定观测序列求状态序列，对字组成的序列，求解对应的标注\n",
    "        '''\n",
    "        # 问题：整条链比较长的情况下，小概率相乘容易造成下溢\n",
    "        # 所以可以采用对数概率，将小概率转化为负数，相乘转化为相加\n",
    "        A = torch.log(self.A)\n",
    "        B = torch.log(self.B)\n",
    "        Pi = torch.log(self.Pi)\n",
    "        \n",
    "        # 初始化viterbi矩阵，它的维度为[状态数, 序列长度]\n",
    "        # viterbi[i, j]表示标注序列的第j个标注为i的所有单个序列出现的概率最大值\n",
    "        seq_len = len(word_list)\n",
    "        viterbi = torch.zeros(self.N, seq_len)\n",
    "        # backpointer用于回溯\n",
    "        # backpointer[i][j]存储的是：标注序列的第j个标注为i时，第j-1个标注的id\n",
    "        backpointer = torch.zeros(self.N, seq_len).long()\n",
    "        \n",
    "        # self.Pi[i]表示第一个字的标记为i的概率\n",
    "        # Bt[word_id]表示字为word_id的时候，对应各个标记的概率\n",
    "        # self.A.t()[tag_id]表示各个状态转移到tag_id对应的概率\n",
    "        start_wordid = self.word2id.get(word_list[0], None)\n",
    "        Bt = B.t()\n",
    "        if start_wordid is None:\n",
    "            # 如果字不在字典里，则假设状态的概率分布是均匀的\n",
    "            bt = torch.log(torch.ones(self.N) / self.N)\n",
    "        else:\n",
    "            bt = Bt[start_wordid]\n",
    "        viterbi[:, 0] = Pi + bt\n",
    "        backpointer[:, 0] = -1 \n",
    "        \n",
    "        # 递推公式：\n",
    "        # viterbi[tag_id, step] = max(viterbi[:, step-1]+self.A.t()[tag_id]+Bt[word])\n",
    "        for step in range(1, seq_len):\n",
    "            wordid = self.word2id.get(word_list[step], None)\n",
    "            # 如果字不在字典中，则假设为均匀分布\n",
    "            if wordid is None:\n",
    "                # 如果字不在字典中，则假设状态概率分布是均匀的\n",
    "                bt = torch.log(torch.ones(self.N) / self.N)\n",
    "            else:\n",
    "                bt = Bt[wordid]\n",
    "            ## 获取前一个step概率最大的状态，计算当前的概率\n",
    "            for tag_id in range(len(self.tag2id)):\n",
    "                max_prob, max_id = torch.max(viterbi[:, step-1] + A[:, tag_id],\n",
    "                                            dim=0)\n",
    "                viterbi[tag_id, step] = max_prob + bt[tag_id]\n",
    "                backpointer[tag_id, step] = max_id\n",
    "\n",
    "        # 终止，t=seq_len，即viterbi[:, seq_len]中的最大概率，就是最优路径的概率\n",
    "        best_path_prob, best_path_pointer = torch.max(\n",
    "            viterbi[:, seq_len-1], dim=0\n",
    "        )\n",
    "\n",
    "        # 回溯，求最优路径\n",
    "        best_path_pointer = best_path_pointer.item()\n",
    "        best_path = [best_path_pointer]\n",
    "        for back_step in range(seq_len-1, 0, -1):\n",
    "            best_path_pointer = backpointer[best_path_pointer, back_step]\n",
    "            best_path_pointer = best_path_pointer.item()\n",
    "            best_path.append(best_path_pointer)\n",
    "\n",
    "        # 将 tag_id组成的序列转化为tag\n",
    "        assert len(best_path) == len(word_list)\n",
    "        id2tag = dict((id_, tag) for tag, id_ in self.tag2id.items())\n",
    "        tag_list = [id2tag[id_] for id_ in reversed(best_path)]\n",
    "\n",
    "        return tag_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcess.data import build_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_lists, train_tag_lists, word2id, tag2id = build_corpus(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_word_lists, dev_tag_lists = build_corpus(\"dev\", make_vocab=False)\n",
    "test_word_lists, test_tag_lists = build_corpus(\"test\", make_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcess.utils import save_model\n",
    "from DataProcess.evaluating import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_train_eval(train_data, test_data, word2id, tag2id, remove_O=False):\n",
    "    '''\n",
    "    训练并评估模型\n",
    "    '''\n",
    "    train_word_lists, train_tag_lists = train_data\n",
    "    test_word_lists, test_tag_lists = test_data\n",
    "    \n",
    "    hmm_model = HMM(len(tag2id), len(word2id), word2id, tag2id)\n",
    "    hmm_model.train(train_word_lists, train_tag_lists)\n",
    "    \n",
    "    save_model(hmm_model, './ckpts/hmm.pkl')\n",
    "    # 评估hmm模型\n",
    "    pred_tag_lists = hmm_model.test(test_word_lists)\n",
    "    metrics = Metrics(test_tag_lists, pred_tag_lists, remove_O=remove_O)\n",
    "    metrics.report_scores()\n",
    "    metrics.report_confusion_matrix()\n",
    "    \n",
    "    return pred_tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "   B-RACE     1.0000    0.9286    0.9630        14\n",
      "   B-NAME     0.9800    0.8750    0.9245       112\n",
      "  M-TITLE     0.9038    0.8751    0.8892      1922\n",
      "    B-LOC     0.3333    0.3333    0.3333         6\n",
      "    E-ORG     0.8262    0.8680    0.8466       553\n",
      "    E-PRO     0.6512    0.8485    0.7368        33\n",
      "    E-LOC     0.5000    0.5000    0.5000         6\n",
      "   M-CONT     0.9815    1.0000    0.9907        53\n",
      "  B-TITLE     0.8811    0.8925    0.8867       772\n",
      "    M-ORG     0.9002    0.9327    0.9162      4325\n",
      "   E-RACE     1.0000    0.9286    0.9630        14\n",
      "  E-TITLE     0.9514    0.9637    0.9575       772\n",
      "    B-EDU     0.9000    0.9643    0.9310       112\n",
      "   E-CONT     0.9655    1.0000    0.9825        28\n",
      "        O     0.9568    0.9177    0.9369      5190\n",
      "    E-EDU     0.9167    0.9821    0.9483       112\n",
      "    B-ORG     0.8422    0.8879    0.8644       553\n",
      "    M-EDU     0.9348    0.9609    0.9477       179\n",
      "   E-NAME     0.9000    0.8036    0.8491       112\n",
      "    B-PRO     0.5581    0.7273    0.6316        33\n",
      "   B-CONT     0.9655    1.0000    0.9825        28\n",
      "    M-PRO     0.4490    0.6471    0.5301        68\n",
      "    M-LOC     0.5833    0.3333    0.4242        21\n",
      "   M-NAME     0.9459    0.8537    0.8974        82\n",
      "avg/total     0.9149    0.9122    0.9130     15100\n",
      "\n",
      "Confusion Matrix:\n",
      "         B-RACE  B-NAME M-TITLE   B-LOC   E-ORG   E-PRO   E-LOC  M-CONT B-TITLE   M-ORG  E-RACE E-TITLE   B-EDU  E-CONT       O   E-EDU   B-ORG   M-EDU  E-NAME   B-PRO  B-CONT   M-PRO   M-LOC  M-NAME \n",
      " B-RACE      13       0       0       0       0       0       0       0       0       0       0       0       0       0       1       0       0       0       0       0       0       0       0       0 \n",
      " B-NAME       0      98       0       0       0       0       0       0       0       2       0       0       0       0       8       0       1       0       0       0       0       0       0       0 \n",
      "M-TITLE       0       0    1682       0      17       3       0       0      35     115       0       6       2       0      44       3       3       4       0       1       0       7       0       0 \n",
      "  B-LOC       0       0       0       2       0       0       0       0       0       0       0       0       0       0       1       0       3       0       0       0       0       0       0       0 \n",
      "  E-ORG       0       0      18       0     480       0       0       0       9      30       0       1       1       0      10       0       0       0       0       1       0       3       0       0 \n",
      "  E-PRO       0       0       0       0       2      28       0       0       0       0       0       0       1       0       0       1       0       1       0       0       0       0       0       0 \n",
      "  E-LOC       0       0       0       0       0       0       3       0       0       1       0       0       0       0       2       0       0       0       0       0       0       0       0       0 \n",
      " M-CONT       0       0       0       0       0       0       0      53       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      "B-TITLE       0       0      28       0       1       0       0       0     689      23       0       1       2       0      20       0       6       0       0       2       0       0       0       0 \n",
      "  M-ORG       0       1      53       0      42       7       3       1      17    4034       0       4       3       1      70       3      38       1       2      10       0      25       5       2 \n",
      " E-RACE       0       0       0       0       0       0       0       0       0       0      13       0       0       0       1       0       0       0       0       0       0       0       0       0 \n",
      "E-TITLE       0       0       2       0       0       0       0       0       0      15       0     744       0       0       6       1       4       0       0       0       0       0       0       0 \n",
      "  B-EDU       0       0       0       0       0       0       0       0       0       1       0       0     108       0       0       0       0       3       0       0       0       0       0       0 \n",
      " E-CONT       0       0       0       0       0       0       0       0       0       0       0       0       0      28       0       0       0       0       0       0       0       0       0       0 \n",
      "      O       0       0      78       0      30       4       0       0      26     204       0      26       1       0    4763       2      37       1       2       3       0      12       0       0 \n",
      "  E-EDU       0       0       0       0       0       1       0       0       0       0       0       0       0       0       0     110       0       1       0       0       0       0       0       0 \n",
      "  B-ORG       0       1       0       3       0       0       0       0       6      23       0       0       0       0      28       0     491       0       0       0       1       0       0       0 \n",
      "  M-EDU       0       0       0       0       1       0       0       0       0       0       0       0       0       0       1       0       0     172       0       1       0       4       0       0 \n",
      " E-NAME       0       0       0       0       3       0       0       0       0       0       0       0       0       0      16       0       0       0      90       0       0       0       0       2 \n",
      "  B-PRO       0       0       0       0       0       0       0       0       0       5       0       0       1       0       0       0       0       0       0      24       0       3       0       0 \n",
      " B-CONT       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0      28       0       0       0 \n",
      "  M-PRO       0       0       0       0       3       0       0       0       0      18       0       0       1       0       0       0       0       1       0       1       0      44       0       0 \n",
      "  M-LOC       0       0       0       1       2       0       0       0       0       7       0       0       0       0       4       0       0       0       0       0       0       0       7       0 \n",
      " M-NAME       0       0       0       0       0       0       0       0       0       3       0       0       0       0       3       0       0       0       6       0       0       0       0      70 \n"
     ]
    }
   ],
   "source": [
    "hmm_pred = hmm_train_eval((train_word_lists, train_tag_lists), (test_word_lists, test_tag_lists),\n",
    "                         word2id, tag2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
