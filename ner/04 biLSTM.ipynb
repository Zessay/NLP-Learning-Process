{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcess.model_utils import tensorized, sort_by_lengths, cal_loss, cal_lstm_crf_loss\n",
    "from models import TrainingConfig, LSTMConfig\n",
    "from models import BiLSTM, BiLSTM_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_Model:\n",
    "    def __init__(self, wor2id, tag2id, vocab_size, out_size, crf=True):\n",
    "        '''\n",
    "        vocab_size: 词典的大小\n",
    "        out_size: 标注的种类\n",
    "        '''\n",
    "        # 加载模型参数\n",
    "        self.emb_size = LSTMConfig.emb_size\n",
    "        self.hidden_size = LSTMConfig.hidden_size\n",
    "        self.crf = crf\n",
    "        \n",
    "        self.word2id = word2id\n",
    "        self.tag2id = tag2id\n",
    "        \n",
    "        # 根据是否添加crf初始化不同的模型，选择不一样的损失计算函数\n",
    "        if not crf:\n",
    "            self.model = BiLSTM(vocab_size, self.emb_size,\n",
    "                               self.hidden_size, out_size, tag2id).to(device)\n",
    "            self.cal_loss_func = cal_loss\n",
    "        else:\n",
    "            self.model = BiLSTM_CRF(vocab_size, self.emb_size,\n",
    "                                   self.hidden_size, out_size, tag2id).to(device)\n",
    "            self.cal_loss_func = cal_lstm_crf_loss\n",
    "            \n",
    "        # 加载训练参数\n",
    "        self.epochs = TrainingConfig.epochs\n",
    "        self.print_step = TrainingConfig.print_step\n",
    "        self.lr = TrainingConfig.lr \n",
    "        self.batch_size = TrainingConfig.batch_size\n",
    "        \n",
    "        # 初始化优化器\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        \n",
    "        # 初始化其他指标\n",
    "        self.step = 0\n",
    "        self._best_val_loss = 1e18\n",
    "        self.best_model = None\n",
    "        \n",
    "    def train(self, word_lists, tag_lists, dev_word_lists, dev_tag_lists):\n",
    "        # 对数据集按照长度进行排序\n",
    "        word_lists, tag_lists, _ = sort_by_lengths(word_lists, tag_lists)\n",
    "        dev_word_lists, dev_tag_lists, _ = sort_by_lengths(dev_word_lists, dev_tag_lists)\n",
    "        \n",
    "        B = self.batch_size\n",
    "        total_step = (len(word_lists) // B + 1)\n",
    "        for e in range(1, self.epochs+1):\n",
    "            step = 0\n",
    "            losses = 0. \n",
    "            for ind in range(0, len(word_lists), B):\n",
    "                step += 1 \n",
    "                batch_sents = word_lists[ind:ind+B]\n",
    "                batch_tags = tag_lists[ind:ind+B]\n",
    "                losses += self.train_step(batch_sents, batch_tags)\n",
    "                if step % self.print_step == 0:\n",
    "                    print(\"Epoch {} | step/total_step: {}/{} {:.2f}% | Loss: {:.4f}\".format(\n",
    "                            e, step, total_step, \n",
    "                            100. * step / total_step,\n",
    "                            losses / self.print_step))\n",
    "                losses = 0.\n",
    "        # 每轮结束测试在验证集上的性能，保存最好的一个\n",
    "        val_loss = self.validate(dev_word_lists, dev_tag_lists)\n",
    "        print(\"Epoch: {} | Val Loss: {:.4f}\".format(e, val_loss))\n",
    "        \n",
    "    def train_step(self, batch_sents, batch_tags):\n",
    "        self.model.train()\n",
    "        # 准备数据\n",
    "        ## 将索引进行向量化，按照第0个索引的位置为最大长度，获取每个单词的index\n",
    "        tensorized_sents, lengths = tensorized(batch_sents, self.word2id)\n",
    "        tensorized_sents = tensorized_sents.to(device)\n",
    "        \n",
    "        ## 同上，只不过是将tag转换为索引\n",
    "        targets, lengths = tensorized(batch_tags, self.tag2id)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        scores = self.model(tensorized_sents, lengths)\n",
    "        \n",
    "        # 计算损失，更新参数\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.cal_loss_func(scores, targets, self.tag2id).to(device)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def validate(self, dev_word_lists, dev_tag_lists):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_losses = 0.\n",
    "            val_step = 0 \n",
    "            for ind in range(0, len(dev_word_lists), self.batch_size):\n",
    "                val_step += 1 \n",
    "                # 准备batch数据\n",
    "                batch_sents = dev_word_lists[ind:ind+self.batch_size]\n",
    "                batch_tags = dev_tag_lists[ind:ind+self.batch_size]\n",
    "                tensorized_sents, lengths = tensorized(batch_sents, self.word2id)\n",
    "                tensorized_sents = tensorized_sents.to(device)\n",
    "                targets, lengths = tensorized(batch_tags, self.tag2id)\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # 前向传播\n",
    "                scores = self.model(tensorized_sents, lengths)\n",
    "                # 计算损失\n",
    "                loss = self.cal_loss_func(\n",
    "                    scores, targets, self.tag2id\n",
    "                ).to(device)\n",
    "                val_losses += loss.item()\n",
    "            val_loss = val_losses / val_step\n",
    "            if val_loss < self._best_val_loss:\n",
    "                print(\"保存模型...\")\n",
    "                self.best_model = copy.deepcopy(self.model)\n",
    "                self._best_val_loss = val_loss\n",
    "            return val_loss\n",
    "        \n",
    "    def test(self, word_lists, tag_lists):\n",
    "        '''\n",
    "        返回最佳模型在测试集上的结果\n",
    "        '''\n",
    "        ## 将要预测的单词列表和tag列表按照长度进行排序，并进行向量化\n",
    "        word_lists, tag_lists, indices = sort_by_lengths(word_lists, tag_lists)\n",
    "        tensorized_sents, lengths = tensorized(word_lists, self.word2id)\n",
    "        tensorized_sents = tensorized_sents.to(device)\n",
    "#         lengths = lengths.to(device)\n",
    "        \n",
    "#         self.best_model.to(device)\n",
    "        self.best_model.eval()\n",
    "        ## 得到预测的tag数据\n",
    "        with torch.no_grad():\n",
    "            batch_tagids = self.best_model.test(tensorized_sents, lengths)\n",
    "            \n",
    "        # 将id转化为标注\n",
    "        pred_tag_lists = []\n",
    "        id2tag = dict((id_, tag) for tag, id_ in self.tag2id.items())\n",
    "        for i, ids in enumerate(batch_tagids):\n",
    "            tag_list = []\n",
    "            if self.crf:\n",
    "                ## 对于crf要去掉最后的<end>标记\n",
    "                for j in range(lengths[i] - 1):\n",
    "                    tag_list.append(id2tag[ids[j].item()])\n",
    "            else:\n",
    "                for j in range(lengths[i]):\n",
    "                    tag_list.append(id2tag[ids[j].item()])\n",
    "            pred_tag_lists.append(tag_list)\n",
    "        \n",
    "        # indices存有根据长度排序的顺序信息\n",
    "        ind_maps = sorted(list(enumerate(indices)), key=lambda e: e[1])\n",
    "        ## 获取原始的顺序\n",
    "        indices, _ = list(zip(*ind_maps))\n",
    "        pred_tag_lists = [pred_tag_lists[i] for i in indices]\n",
    "        tag_lists = [tag_lists[i] for i in indices]\n",
    "        \n",
    "        return pred_tag_lists, tag_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcess.data import build_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_word_lists, train_tag_lists, word2id, tag2id = build_corpus(\"train\")\n",
    "dev_word_lists, dev_tag_lists = build_corpus(\"dev\", make_vocab=False)\n",
    "test_word_lists, test_tag_lists = build_corpus(\"test\", make_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataProcess.utils import extend_maps, preprocess_data_for_lstmcrf\n",
    "from DataProcess.utils import save_model, flatten_lists\n",
    "from DataProcess.evaluating import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义bilstm+crf的训练函数\n",
    "def bilstm_train_and_eval(train_data, dev_data, test_data, word2id, tag2id,\n",
    "                         crf=True, remove_O=False):\n",
    "    train_word_lists, train_tag_lists = train_data\n",
    "    dev_word_lists, dev_tag_lists = dev_data\n",
    "    test_word_lists, test_tag_lists = test_data\n",
    "    start = time.time()\n",
    "    vocab_size = len(word2id)\n",
    "    out_size = len(tag2id)\n",
    "    bilstm_model = BiLSTM_Model(word2id, tag2id, vocab_size, out_size, crf=crf)\n",
    "    bilstm_model.train(train_word_lists, train_tag_lists, \n",
    "                      dev_word_lists, dev_tag_lists)\n",
    "    model_name = \"bilstm_crf\" if crf else \"bilstm\"\n",
    "    save_model(bilstm_model, \"./ckpts/\"+model_name+\".pkl\")\n",
    "    \n",
    "    print(\"训练完毕，共用时{}秒\".format(int(time.time()-start)))\n",
    "    print(\"评估 {} 模型中...\".format(model_name))\n",
    "    pred_tag_lists, test_tag_lists = bilstm_model.test(test_word_lists,\n",
    "                                                      test_tag_lists)\n",
    "    \n",
    "    metrics = Metrics(test_tag_lists, pred_tag_lists, remove_O=remove_O)\n",
    "    metrics.report_scores()\n",
    "    metrics.report_confusion_matrix()\n",
    "    \n",
    "    return pred_tag_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练并测试bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在训练评估BiLSTM模型....\n",
      "Epoch 1 | step/total_step: 15/60 25.00% | Loss: 0.1432\n",
      "Epoch 1 | step/total_step: 30/60 50.00% | Loss: 0.0839\n",
      "Epoch 1 | step/total_step: 45/60 75.00% | Loss: 0.0584\n",
      "Epoch 1 | step/total_step: 60/60 100.00% | Loss: 0.0859\n",
      "Epoch 2 | step/total_step: 15/60 25.00% | Loss: 0.0459\n",
      "Epoch 2 | step/total_step: 30/60 50.00% | Loss: 0.0400\n",
      "Epoch 2 | step/total_step: 45/60 75.00% | Loss: 0.0292\n",
      "Epoch 2 | step/total_step: 60/60 100.00% | Loss: 0.0395\n",
      "Epoch 3 | step/total_step: 15/60 25.00% | Loss: 0.0242\n",
      "Epoch 3 | step/total_step: 30/60 50.00% | Loss: 0.0222\n",
      "Epoch 3 | step/total_step: 45/60 75.00% | Loss: 0.0184\n",
      "Epoch 3 | step/total_step: 60/60 100.00% | Loss: 0.0262\n",
      "Epoch 4 | step/total_step: 15/60 25.00% | Loss: 0.0156\n",
      "Epoch 4 | step/total_step: 30/60 50.00% | Loss: 0.0138\n",
      "Epoch 4 | step/total_step: 45/60 75.00% | Loss: 0.0126\n",
      "Epoch 4 | step/total_step: 60/60 100.00% | Loss: 0.0183\n",
      "Epoch 5 | step/total_step: 15/60 25.00% | Loss: 0.0118\n",
      "Epoch 5 | step/total_step: 30/60 50.00% | Loss: 0.0099\n",
      "Epoch 5 | step/total_step: 45/60 75.00% | Loss: 0.0089\n",
      "Epoch 5 | step/total_step: 60/60 100.00% | Loss: 0.0131\n",
      "保存模型...\n",
      "Epoch: 5 | Val Loss: 0.2042\n",
      "训练完毕，共用时19秒\n",
      "评估 bilstm 模型中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1236: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "   M-CONT     1.0000    1.0000    1.0000        53\n",
      "  M-TITLE     0.8824    0.8866    0.8845      1922\n",
      "    M-EDU     0.9253    0.8994    0.9122       179\n",
      "    E-PRO     0.7895    0.9091    0.8451        33\n",
      "    M-LOC     0.8667    0.6190    0.7222        21\n",
      "   E-NAME     0.9725    0.9464    0.9593       112\n",
      "    B-PRO     1.0000    0.6667    0.8000        33\n",
      "    E-ORG     0.9343    0.8481    0.8891       553\n",
      "   E-CONT     1.0000    1.0000    1.0000        28\n",
      "   B-RACE     1.0000    1.0000    1.0000        14\n",
      "    M-ORG     0.9359    0.9683    0.9518      4325\n",
      "    E-EDU     0.9623    0.9107    0.9358       112\n",
      "  B-TITLE     0.9394    0.8834    0.9105       772\n",
      "    B-LOC     1.0000    0.5000    0.6667         6\n",
      "    M-PRO     0.7375    0.8676    0.7973        68\n",
      "   E-RACE     1.0000    1.0000    1.0000        14\n",
      "   B-CONT     0.9655    1.0000    0.9825        28\n",
      "   B-NAME     0.9341    0.7589    0.8374       112\n",
      "   M-NAME     0.7660    0.8780    0.8182        82\n",
      "    E-LOC     0.0000    0.0000    0.0000         6\n",
      "        O     0.9664    0.9649    0.9657      5190\n",
      "  E-TITLE     0.9705    0.9793    0.9749       772\n",
      "    B-EDU     0.9528    0.9018    0.9266       112\n",
      "    B-ORG     0.9527    0.9114    0.9316       553\n",
      "avg/total     0.9406    0.9405    0.9401     15100\n",
      "\n",
      "Confusion Matrix:\n",
      "         M-CONT M-TITLE   M-EDU   E-PRO   M-LOC  E-NAME   B-PRO   E-ORG  E-CONT  B-RACE   M-ORG   E-EDU B-TITLE   B-LOC   M-PRO  E-RACE  B-CONT  B-NAME  M-NAME   E-LOC       O E-TITLE   B-EDU   B-ORG \n",
      " M-CONT      53       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      "M-TITLE       0    1704       3       1       0       0       0       8       0       0      96       1      22       0       2       0       1       0       0       0      71      12       0       1 \n",
      "  M-EDU       0       1     161       0       0       0       0       1       0       0       8       2       0       0       3       0       0       0       0       0       2       0       1       0 \n",
      "  E-PRO       0       0       1      30       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       1       0       1       0 \n",
      "  M-LOC       0       6       0       0      13       0       0       1       0       0       1       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      " E-NAME       0       0       0       0       0     106       0       0       0       0       0       0       0       0       0       0       0       1       2       0       3       0       0       0 \n",
      "  B-PRO       0       0       0       0       0       0      22       0       0       0       3       0       0       0       8       0       0       0       0       0       0       0       0       0 \n",
      "  E-ORG       0      40       1       0       0       0       0     469       0       0      33       0       0       0       1       0       0       0       0       0       8       1       0       0 \n",
      " E-CONT       0       0       0       0       0       0       0       0      28       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      " B-RACE       0       0       0       0       0       0       0       0       0      14       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      "  M-ORG       0      64       0       2       0       0       0      14       0       0    4188       0       7       0       4       0       0       0       0       0      38       0       2       6 \n",
      "  E-EDU       0       0       3       1       0       0       0       0       0       0       2     102       0       0       0       0       0       0       0       0       4       0       0       0 \n",
      "B-TITLE       0      49       0       0       0       0       0       1       0       0      16       0     682       0       0       0       0       0       0       0      12       2       1       9 \n",
      "  B-LOC       0       0       0       0       0       0       0       0       0       0       0       0       2       3       0       0       0       0       0       0       0       0       0       1 \n",
      "  M-PRO       0       0       0       1       0       0       0       1       0       0       7       0       0       0      59       0       0       0       0       0       0       0       0       0 \n",
      " E-RACE       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0      14       0       0       0       0       0       0       0       0 \n",
      " B-CONT       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0      28       0       0       0       0       0       0       0 \n",
      " B-NAME       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0      85      20       0       7       0       0       0 \n",
      " M-NAME       0       0       0       0       0       2       0       0       0       0       0       0       0       0       0       0       0       5      72       0       3       0       0       0 \n",
      "  E-LOC       0       0       0       0       2       1       0       0       0       0       0       0       0       0       0       0       0       0       0       0       1       2       0       0 \n",
      "      O       0      62       0       0       0       0       0       7       0       0      90       0       6       0       3       0       0       0       0       0    5008       6       0       8 \n",
      "E-TITLE       0       4       0       0       0       0       0       0       0       0       2       1       0       0       0       0       0       0       0       0       9     756       0       0 \n",
      "  B-EDU       0       0       5       3       0       0       0       0       0       0       2       0       0       0       0       0       0       0       0       0       1       0     101       0 \n",
      "  B-ORG       0       1       0       0       0       0       0       0       0       0      27       0       7       0       0       0       0       0       0       0      14       0       0     504 \n"
     ]
    }
   ],
   "source": [
    "print(\"正在训练评估BiLSTM模型....\")\n",
    "lstm_pred = bilstm_train_and_eval((train_word_lists, train_tag_lists),\n",
    "                                 (dev_word_lists, dev_tag_lists), \n",
    "                                 (test_word_lists, test_tag_lists),\n",
    "                                 word2id, tag2id,\n",
    "                                 crf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练并评估BiLSTM+CRF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | step/total_step: 15/60 25.00% | Loss: 5.4931\n",
      "Epoch 1 | step/total_step: 30/60 50.00% | Loss: 2.2889\n",
      "Epoch 1 | step/total_step: 45/60 75.00% | Loss: 1.0327\n",
      "Epoch 1 | step/total_step: 60/60 100.00% | Loss: 0.4880\n",
      "Epoch 2 | step/total_step: 15/60 25.00% | Loss: 1.8321\n",
      "Epoch 2 | step/total_step: 30/60 50.00% | Loss: 1.1308\n",
      "Epoch 2 | step/total_step: 45/60 75.00% | Loss: 0.5760\n",
      "Epoch 2 | step/total_step: 60/60 100.00% | Loss: 0.3126\n",
      "Epoch 3 | step/total_step: 15/60 25.00% | Loss: 0.9648\n",
      "Epoch 3 | step/total_step: 30/60 50.00% | Loss: 0.6490\n",
      "Epoch 3 | step/total_step: 45/60 75.00% | Loss: 0.3618\n",
      "Epoch 3 | step/total_step: 60/60 100.00% | Loss: 0.1841\n",
      "Epoch 4 | step/total_step: 15/60 25.00% | Loss: 0.6024\n",
      "Epoch 4 | step/total_step: 30/60 50.00% | Loss: 0.4230\n",
      "Epoch 4 | step/total_step: 45/60 75.00% | Loss: 0.2552\n",
      "Epoch 4 | step/total_step: 60/60 100.00% | Loss: 0.1357\n",
      "Epoch 5 | step/total_step: 15/60 25.00% | Loss: 0.4383\n",
      "Epoch 5 | step/total_step: 30/60 50.00% | Loss: 0.2991\n",
      "Epoch 5 | step/total_step: 45/60 75.00% | Loss: 0.1903\n",
      "Epoch 5 | step/total_step: 60/60 100.00% | Loss: 0.1067\n",
      "保存模型...\n",
      "Epoch: 5 | Val Loss: 5.6961\n",
      "训练完毕，共用时30秒\n",
      "评估 bilstm_crf 模型中...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1565272271120/work/aten/src/ATen/native/cudnn/RNN.cpp:1236: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "   E-NAME     0.9358    0.9107    0.9231       112\n",
      "   B-CONT     0.9032    1.0000    0.9492        28\n",
      "   M-CONT     0.9138    1.0000    0.9550        53\n",
      "   E-CONT     1.0000    1.0000    1.0000        28\n",
      "    B-EDU     0.9505    0.8571    0.9014       112\n",
      "    M-LOC     0.9333    0.6667    0.7778        21\n",
      "  E-TITLE     0.9754    0.9741    0.9747       772\n",
      "    E-PRO     0.9118    0.9394    0.9254        33\n",
      "    B-LOC     0.0000    0.0000    0.0000         6\n",
      "   E-RACE     1.0000    1.0000    1.0000        14\n",
      "    M-PRO     0.6742    0.8824    0.7643        68\n",
      "    B-PRO     0.8333    0.6061    0.7018        33\n",
      "  B-TITLE     0.9296    0.9067    0.9180       772\n",
      "    E-LOC     1.0000    0.1667    0.2857         6\n",
      "    E-ORG     0.9268    0.8698    0.8974       553\n",
      "    E-EDU     0.9541    0.9286    0.9412       112\n",
      "        O     0.9682    0.9509    0.9595      5190\n",
      "   B-NAME     0.9694    0.8482    0.9048       112\n",
      "  M-TITLE     0.9196    0.8866    0.9028      1922\n",
      "    M-EDU     0.8804    0.9050    0.8926       179\n",
      "   B-RACE     1.0000    0.9286    0.9630        14\n",
      "    B-ORG     0.9677    0.9222    0.9444       553\n",
      "   M-NAME     0.9726    0.8659    0.9161        82\n",
      "    M-ORG     0.9176    0.9757    0.9458      4325\n",
      "avg/total     0.9405    0.9400    0.9396     15100\n",
      "\n",
      "Confusion Matrix:\n",
      "         E-NAME  B-CONT  M-CONT  E-CONT   B-EDU   M-LOC E-TITLE   E-PRO   B-LOC  E-RACE   M-PRO   B-PRO B-TITLE   E-LOC   E-ORG   E-EDU       O  B-NAME M-TITLE   M-EDU  B-RACE   B-ORG  M-NAME   M-ORG \n",
      " E-NAME     102       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       9       1       0       0       0       0       0       0 \n",
      " B-CONT       0      28       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      " M-CONT       0       0      53       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      " E-CONT       0       0       0      28       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      "  B-EDU       0       0       0       0      96       0       0       0       0       0       0       0       0       0       0       0       1       1       0      11       0       1       0       2 \n",
      "  M-LOC       0       0       0       0       0      14       0       0       0       0       0       0       0       0       0       0       1       0       0       0       0       0       0       6 \n",
      "E-TITLE       0       0       0       0       0       0     752       0       0       0       0       0       0       0       0       1      11       0       8       0       0       0       0       0 \n",
      "  E-PRO       0       0       0       0       0       0       0      31       0       0       0       0       0       0       0       0       0       0       0       2       0       0       0       0 \n",
      "  B-LOC       0       0       0       0       1       0       0       0       0       0       0       0       1       0       0       0       2       0       0       0       0       2       0       0 \n",
      " E-RACE       0       0       0       0       0       0       0       0       0      14       0       0       0       0       0       0       0       0       0       0       0       0       0       0 \n",
      "  M-PRO       0       0       0       0       0       0       0       0       0       0      60       0       0       0       0       0       0       0       0       0       0       0       0       8 \n",
      "  B-PRO       0       0       0       0       1       0       0       0       0       0       7      20       1       0       0       0       0       0       0       0       0       0       0       4 \n",
      "B-TITLE       0       0       0       0       2       0       1       0       0       0       0       0     700       0       5       0       9       0      33       0       0       8       0      14 \n",
      "  E-LOC       2       0       0       0       0       1       1       0       0       0       0       0       0       1       0       0       1       0       0       0       0       0       0       0 \n",
      "  E-ORG       0       0       0       0       0       0       1       0       0       0       4       0       4       0     481       0       4       0      25       0       0       0       0      34 \n",
      "  E-EDU       0       0       0       0       0       0       0       1       0       0       0       0       0       0       0     104       1       0       0       4       0       0       0       2 \n",
      "      O       0       3       4       0       0       0       8       0       0       0       3       1      11       0       8       0    4935       0      39       1       0       6       1     170 \n",
      " B-NAME       1       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0      15      95       0       0       0       0       1       0 \n",
      "M-TITLE       0       0       0       0       0       0       8       1       0       0       2       0      25       0      11       1      62       0    1704       4       0       0       0     104 \n",
      "  M-EDU       0       0       0       0       0       0       0       0       0       0       4       1       0       0       1       3       1       0       0     162       0       0       0       7 \n",
      " B-RACE       0       0       0       0       1       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0      13       0       0       0 \n",
      "  B-ORG       0       0       0       0       0       0       0       0       0       0       0       0       7       0       0       0       8       0       0       0       0     510       0      28 \n",
      " M-NAME       4       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       6       1       0       0       0       0      71       0 \n",
      "  M-ORG       0       0       1       0       0       0       0       1       0       0       9       2       4       0      13       0      31       0      44       0       0       0       0    4220 \n"
     ]
    }
   ],
   "source": [
    "crf_word2id, crf_tag2id = extend_maps(word2id, tag2id)\n",
    "# 还要对数据进行一些额外处理\n",
    "train_word_lists, train_tag_lists = preprocess_data_for_lstmcrf(train_word_lists, train_tag_lists)\n",
    "dev_word_lists, dev_tag_lists = preprocess_data_for_lstmcrf(dev_word_lists, dev_tag_lists)\n",
    "test_word_lists, test_tag_lists = preprocess_data_for_lstmcrf(test_word_lists, test_tag_lists, test=True)\n",
    "\n",
    "\n",
    "lstmcrf_pred = bilstm_train_and_eval(\n",
    "    (train_word_lists, train_tag_lists),\n",
    "    (dev_word_lists, dev_tag_lists),\n",
    "    (test_word_lists, test_tag_lists),\n",
    "    crf_word2id, crf_tag2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch_test]",
   "language": "python",
   "name": "conda-env-torch_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
